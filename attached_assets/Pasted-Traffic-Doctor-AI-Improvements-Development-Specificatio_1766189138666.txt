Traffic Doctor AI Improvements — Development Specifications

0) Objective

Increase diagnostic accuracy and actionability for organic traffic drops (GA4 + GSC first; Ads optional later) by:
	•	enforcing evidence-based conclusions
	•	adding deterministic classification forks (impressions vs clicks)
	•	detecting template/cluster regressions
	•	producing confidence-scored hypotheses and decision-oriented tickets

Success criteria:
	•	Every run produces: (a) a primary root-cause classification, (b) top 3 hypotheses with confidence + evidence, (c) top 10 tickets with quantified impact, (d) explicit “what data is missing” if inconclusive.
	•	Reduce “algorithm update” as default explanation to <5% of runs unless supported by evidence gates.

⸻

1) Data Model Changes (DB)

1.1 New Tables

runs
Stores each analysis execution.
	•	id (uuid, pk)
	•	started_at (timestamp)
	•	finished_at (timestamp)
	•	status (enum: running|completed|failed)
	•	error_summary (text, nullable)
	•	env (text)
	•	source_status (jsonb)  // per-source ok/error + timings
	•	primary_classification (text, nullable)  // see §3
	•	confidence_overall (enum: high|medium|low, nullable)

gsc_page_daily
Page-level rollups (derived from raw GSC pulls).
	•	run_id (uuid, fk runs.id)
	•	date (date)
	•	page_path (text)  // relative path only
	•	clicks (int)
	•	impressions (int)
	•	ctr (float)
	•	position (float)

gsc_query_daily
Query-level rollups.
	•	run_id
	•	date
	•	query (text)
	•	clicks
	•	impressions
	•	ctr
	•	position

ga4_landing_daily
Landing page rollups.
	•	run_id
	•	date
	•	landing_path (text)
	•	sessions (int)
	•	users (int)
	•	engaged_sessions (int, optional)
	•	conversions (int, optional)

anomalies
Detected anomalies for each run.
	•	id (uuid, pk)
	•	run_id (uuid, fk)
	•	anomaly_type (enum: traffic_drop|impressions_drop|ctr_drop|page_cluster_drop|tracking_gap)
	•	start_date (date)
	•	end_date (date)
	•	metric (text)
	•	baseline_value (float)
	•	observed_value (float)
	•	delta_pct (float)
	•	z_score (float)
	•	scope (jsonb) // e.g., channel=Organic Search, page_cluster=/services/*

hypotheses
Ranked hypotheses with confidence + evidence.
	•	id (uuid, pk)
	•	run_id
	•	rank (int)
	•	hypothesis_key (enum; see §4)
	•	confidence (enum: high|medium|low)
	•	summary (text)
	•	evidence (jsonb) // list of evidence blocks
	•	disconfirmed_by (jsonb, nullable) // evidence that weakens it
	•	missing_data (jsonb, nullable) // what would increase confidence

tickets
Action tickets generated from hypotheses.
	•	id (uuid, pk)
	•	run_id
	•	owner (enum: SEO|DEV|ADS)
	•	priority (enum: P0|P1|P2|P3)
	•	title (text)
	•	steps (jsonb) // ordered steps
	•	expected_impact (enum: high|medium|low)
	•	impact_estimate (jsonb) // e.g., recoverable_clicks, affected_pages_count
	•	evidence (jsonb) // metrics + references
	•	status (enum: open|dismissed|done, default open)

1.2 Extend Existing Tables (if present)

If you already store report and tickets blobs, keep them but ensure they are derived from the new normalized tables above.

⸻

2) Metrics & Derived Features

2.1 Core deltas (must compute each run)

Compute deltas over two windows:
	•	current_window: last 3 days ending run date
	•	baseline_window: previous 14 days ending day before current window

For GA4 (Organic Search channel):
	•	sessions delta %
	•	users delta %

For GSC:
	•	clicks delta %
	•	impressions delta %
	•	ctr delta %
	•	avg position delta

Store these in runs.source_status and anomalies.

2.2 Impressions-vs-clicks fork features

Compute:
	•	impressions_drop_flag (boolean)
	•	clicks_drop_flag (boolean)
	•	ctr_drop_flag (boolean)
with thresholds:
	•	drop_pct <= -30% AND z_score <= -2.0 (configurable)

⸻

3) Primary Classification (Deterministic)

3.1 Classification keys

Set exactly one per run:
	•	VISIBILITY_LOSS (impressions down)
	•	CTR_LOSS (impressions flat, clicks down, ctr down)
	•	PAGE_CLUSTER_REGRESSION (loss concentrated in one or few clusters)
	•	TRACKING_OR_ATTRIBUTION_GAP (GA4 drop without corresponding GSC drop)
	•	INCONCLUSIVE

3.2 Rules (priority order)
	1.	If GA4 Organic sessions down AND GSC clicks+impressions NOT down ⇒ TRACKING_OR_ATTRIBUTION_GAP
	2.	If GSC impressions down significantly ⇒ VISIBILITY_LOSS
	3.	If GSC impressions flat AND clicks down AND ctr down ⇒ CTR_LOSS
	4.	If top cluster accounts for ≥60% of click loss ⇒ PAGE_CLUSTER_REGRESSION
	5.	Else ⇒ INCONCLUSIVE

Persist classification + confidence in runs.

⸻

4) Hypotheses Engine

4.1 Hypothesis keys
	•	ROBOTS_OR_NOINDEX
	•	CANONICAL_MISMATCH
	•	REDIRECT_CHAIN_OR_HTTP_CHANGE
	•	SSR_OR_THIN_CONTENT_REGRESSION
	•	STRUCTURED_DATA_BREAK
	•	INTERNAL_LINKING_BREAK
	•	CONTENT_INTENT_MISMATCH
	•	SERP_LAYOUT_OR_CTR_SHIFT
	•	GOOGLE_UPDATE_OR_INDUSTRY_WIDE
	•	SEASONALITY (rare; gated)
	•	TRACKING_TAG_OR_GA4_CONFIG

4.2 Evidence blocks (standard structure)

Each hypothesis must include ≥2 evidence blocks:
	•	type: metric|check|comparison|log
	•	statement: human-readable claim
	•	data: JSON with numbers/dates/paths
	•	strength: strong|moderate|weak

If evidence insufficient ⇒ confidence must be low and missing_data must be filled.

4.3 Hard gates (prevent lazy explanations)
	•	GOOGLE_UPDATE_OR_INDUSTRY_WIDE can only be rank<=3 if:
	•	no technical hypotheses have confidence high
	•	loss not concentrated in clusters
	•	visibility loss spans multiple query categories
	•	SEASONALITY can only appear if:
	•	pattern repeats in same period in prior year (requires historical) OR
	•	external benchmark provided (optional integration)

⸻

5) Cluster / Template Regression Detection

5.1 Cluster definitions

Create a page_cluster feature for each page path:
	•	rule-based patterns (config file):
	•	/services/*
	•	/locations/*
	•	/conditions/*
	•	/blog/*
	•	/ (home)
	•	fallback: first path segment

5.2 Cluster loss computation

For each cluster, compute click loss contribution:
	•	cluster_click_loss = baseline_clicks - current_clicks
	•	cluster_loss_share = cluster_click_loss / total_click_loss

If any cluster_loss_share >= 0.6, create anomaly page_cluster_drop and set primary classification PAGE_CLUSTER_REGRESSION.

Store top 5 clusters in report.

⸻

6) Website Checks Upgrades (SSR & Signals)

6.1 Required checks per sampled page

For each top landing page (from GA4/GSC):
	•	status code + redirect chain
	•	canonical href and whether matches expected host/path
	•	meta robots and x-robots-tag headers
	•	presence of:
	•	<title> non-empty
	•	single <h1> non-empty
	•	body text length threshold (e.g., >= 300 chars) from raw HTML
	•	detect “JS shell” (body mostly scripts, little text)
	•	structured data present? (JSON-LD blocks count)

Persist each finding; flag regressions vs prior run.

6.2 Regression detection

Compare today’s checks to previous successful run:
	•	if canonical changed
	•	if robots/noindex introduced
	•	if body text length drops >50%
Create hypothesis evidence blocks automatically.

⸻

7) Report Generation Spec (daily_report.md)

7.1 Required sections (in order)
	1.	Executive Summary

	•	Primary classification + confidence
	•	Incident start date(s)
	•	Top 3 drivers (pages/queries/clusters)

	2.	What Changed

	•	GA4 Organic sessions/users deltas
	•	GSC clicks/impressions/ctr/position deltas
	•	Top losing clusters/pages/queries

	3.	Root Cause Hypotheses (ranked)

	•	Each: confidence + evidence bullets

	4.	Recommended Actions (Top 5)

	•	reference ticket IDs

	5.	Missing Data / Next Checks

	•	list exactly what’s needed to raise confidence

⸻

8) Ticket Generation Spec (tickets.json)

8.1 Ticket fields
	•	owner: SEO|DEV|ADS
	•	priority: P0–P3
	•	title: concise
	•	steps: 3–8 actionable steps
	•	expected_impact: high|medium|low
	•	impact_estimate:
	•	affected_pages_count
	•	recoverable_clicks_est (if possible)
	•	evidence:
	•	key metrics with dates
	•	top affected paths/queries
	•	guardrail:
	•	no “check for algorithm updates” as P0 unless gated

8.2 Priority rules
	•	P0: robots/noindex, canonical sitewide mismatch, SSR blank shell, widespread 5xx/4xx spikes
	•	P1: structured data break, internal linking collapse, redirect chain growth
	•	P2: content intent mismatch opportunities, CTR/snippet improvements
	•	P3: monitoring/alerts

⸻

9) AI Analyst Integration (Embedded)

9.1 /ai/ask contract

POST /ai/ask
	•	input: { question: string }
	•	output: { answerMarkdown: string, runId: string, citations: { type, ref }[] }

9.2 Context assembly (no hallucinations)

Provide AI:
	•	primary classification
	•	anomalies list
	•	top losing pages/queries/clusters
	•	top hypotheses with evidence blocks
	•	top tickets

AI must be instructed:
	•	“Use only provided facts; if missing, ask for what data is missing.”

⸻

10) UI Updates

10.1 Dashboard additions
	•	Primary classification badge + confidence
	•	Incident start date
	•	Top losing clusters and pages
	•	Top 5 tickets
	•	“What changed since yesterday” diff view (compare last two runs)

10.2 Ask AI tab
	•	question input
	•	show response
	•	show “based on run  at ”

⸻

11) Alerts & Monitoring

11.1 Alert conditions
	•	P0 anomaly detected
	•	GA4 Organic sessions drop > X%
	•	GSC impressions drop > X%
	•	website check regression triggered

11.2 Delivery
	•	Initially: UI banner + ticket
	•	Later: email/slack webhook (optional)

⸻

12) Acceptance Tests

12.1 Deterministic classification tests

Provide fixture datasets:
	•	visibility loss scenario
	•	CTR-only loss scenario
	•	tracking gap scenario
	•	cluster regression scenario

Assert:
	•	classification matches expected
	•	top hypothesis confidence aligns with evidence
	•	tickets priorities consistent

12.2 Website checks regression tests

Given prior run with good HTML and new run with empty body:
	•	create SSR regression anomaly
	•	generate DEV P0 ticket

12.3 “No data yet” behavior

If no completed run exists:
	•	report/tickets endpoints return 404 with clear message
	•	AI asks user to run diagnosis first

⸻

13) Configuration

Add config options (env or config file):
	•	anomaly thresholds (pct, z-score)
	•	window lengths (current/baseline)
	•	cluster patterns
	•	sample size for page checks
	•	minimum text length thresholds
	•	hypothesis gating toggles

⸻

14) Implementation Order (recommended)
	1.	Add derived deltas + primary classification
	2.	Add cluster regression detection
	3.	Upgrade website checks + regression compare
	4.	Add hypotheses table + evidence blocks + gates
	5.	Generate tickets with priority rules
	6.	Update report format
	7.	Embed AI analyst using normalized outputs
	8.	Add UI diff and confidence display