You are the Replit Agent working inside the Hermes SEO codebase. Your job is to make ONE workflow rock-solid:

**Workflow:** User enters a website URL → clicks **Analyze My Website** → a shareable **SEO report** is generated and displayed reliably, using only public data (no GA/GSC required). The report must always render, even if crawling is blocked.

Do not expand scope beyond this workflow.

---

## Product Definition (v1)

### Core principle

The report is the product. It must be credible, fast, and deterministic using:

* SERP API (rank checks vs selected keywords)
* Competitor discovery from SERP overlap
* Technical crawl data *only if crawl is allowed*

No Google Analytics. No Google Search Console. No OAuth required to generate the report.

### Two report modes (must support both)

1. **Full Visibility Report** (crawl allowed)
2. **Limited Visibility Report** (crawl blocked or fails)

Both must still include competitor + keyword sections.

---

## Implementation Requirements

### 1) “Analyze My Website” must generate a report (end-to-end)

* Add/confirm an API endpoint that accepts `{ url }` and returns `{ scanId }` immediately.
* The scan runs async and writes results to DB keyed by `scanId`.
* The UI should poll `/api/scan/:scanId` until status is `complete` or `failed`, then render the report page.

**Statuses:** `queued | running | complete | failed`
**Retry policy:** If SERP calls fail, retry once. If still failing, continue report with partial data and show a calm “limited data” note.

### 2) Data sources and what to compute (v1)

#### A) Competitors (always)

* Identify 3–5 competitors by SERP overlap:

  * Run SERP queries for the 10 selected keywords
  * Count competitor domains appearing in top 10/20
  * Select top overlap domains (excluding the target domain)
* Output: list of competitor domains + a simple “visibility bar” value (0–100 derived from overlap count)

#### B) Keyword opportunities (always)

* Generate a candidate keyword list using:

  * Extract visible text + headings from homepage + a few top internal pages (or just homepage if limited)
  * Combine with keyword suggestions derived from competitor titles/snippets from SERPs
* Choose **exactly 10** “Priority Keywords”:

  * Prefer high-intent phrases related to site topic/services
  * Output per keyword:

    * keyword
    * estimated volume (if you have a source; if not, omit volume and don’t fake it)
    * current rank (number) or “Not ranking”
    * top 3 domains ranking (optional)

#### C) Technical SEO (conditional)

* Attempt crawl via the existing technical crawler service if configured.
* If crawl succeeds:

  * Include a “Technical Findings” section with:

    * internal broken links count
    * indexability/canonical issues count (if available)
    * top 5 priority issues (human-readable)
* If crawl is blocked/fails:

  * Report switches to “Limited Visibility”
  * Show a clear “Technical visibility is limited” explanation (robots.txt / blocks / timeout)
  * Provide 3 technical next steps that do not require crawling (e.g., allow crawling, submit sitemap, fix robots directives)

### 3) Report rendering

Build a single report page that can render either mode based on available data.

**Report sections (always render these):**

1. SEO Snapshot (compact KPI tiles)
2. Competitors
3. Priority Keywords (Top 10) + ranks
4. What to do next (3–5 bullets based on findings)

**Conditional section:**

* Technical Findings (only in Full Visibility)

Do NOT add GA/GSC metrics in v1 unless they are already available without OAuth.

### 4) Replace CTA: remove “Fix Everything” from report context

On the report page, the primary CTA must be:

* **“Unlock full automation → Sign up”**
  No “Fix Everything” in this funnel.

### 5) Signup must work and preserve scan context

* Signup page supports a query param `scanId=...`
* After signup:

  * user is created
  * scanId is associated with the user account
  * user lands back on the report (or dashboard) with their report preserved

Minimum fields:

* email
* password
* website url (prefill from scan)
  No extra onboarding steps in v1.

### 6) Notify Kevin when anyone signs up

On successful signup, send an email notification to Kevin.

Email requirements:

* Subject: `New Arclo Signup`
* Body includes: email, website, timestamp, scanId

Use the existing SendGrid integration if present (environment already includes SendGrid + FROM email). If SendGrid isn’t wired, implement a server-side email sender module and fail gracefully (log + continue signup).

---

## Engineering Constraints (keep it stable)

### Contract tests (required)

Add a basic test or script that verifies:

* report scan endpoint returns scanId
* scan status transitions to complete with mocked services
* report page renders with both:

  * a full report object
  * a limited report object

### Health check (required)

Add `/api/health` that verifies required env vars exist for:

* SERP API key
* notification email config (SendGrid key + from email)

It should not crash the app if missing; it should return JSON showing what’s configured.

---

## Deliverables Checklist (done = true)

1. Analyze flow: URL → scanId → status polling → report render works
2. Two report modes supported and visually clear
3. Competitors + Top 10 keywords always appear
4. Crawl results appear when available; graceful fallback when blocked
5. Report CTA is “Sign up”
6. Signup works, preserves scanId, associates scan to user
7. Email notification to Kevin fires on signup
8. Minimal tests + /health endpoint exist

---

## Work Plan Order (execute in this exact order)

1. Locate current analyze/report code paths and scan storage
2. Implement/repair scan lifecycle + DB schema for report data
3. Implement competitor + keyword + serp rank logic
4. Implement crawl conditional + fallback logic
5. Build report page renderer for both modes
6. Wire signup scanId association + redirect flow
7. Add signup notification email
8. Add health endpoint + minimal tests

Start now. Stay inside scope. Do not add new product areas.
