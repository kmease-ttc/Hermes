You’ve got it — “Test All Services” right now is basically a *ping*. You need two different buttons and two different behaviors:

1. **Test Connection** = can Hermes reach/auth the worker?
2. **Run Smoke Test** (or “Test Service”) = does the worker actually do the job and return expected outputs?

And “Missing” must be consistent in **both places**:

* the main Integrations table
* the service inspector/modal

Here are developer instructions to implement that cleanly.

---

# Developer Instructions: Split “Test All” into Connection vs Service Tests + Missing Everywhere

## Goal

Add two distinct test flows:

### A) Connection Tests (fast)

* verifies secret + base_url + auth
* calls `/health` (or a lightweight endpoint)
* should never be confused with “service works”

### B) Service Tests (smoke runs)

* triggers a minimal real run per service (mode=smoke)
* captures outputs returned
* computes missing outputs
* updates UI “Missing” in:

  * Integrations list
  * Service inspector

---

## 1) Add two buttons at top of Integrations

### Button 1: “Test Connections”

* Calls: `POST /api/integrations/test-connections`
* Runs in parallel across all **built** services
* Only checks connection (health/auth)

### Button 2: “Run Smoke Tests”

* Calls: `POST /api/integrations/run-smoke-tests`
* Runs real minimal tests across all **built+ready** services
* Can queue async workers and mark “Running”

**Remove/replace** the current “Test All Services” button with these two.

---

## 2) Define two separate run types in `service_runs`

Update `service_runs` to include:

* `run_type`: `"connection" | "smoke" | "full"`

And store:

* `expected_outputs` (from catalog)
* `actual_outputs` (from worker response)
* `missing_outputs` (computed)

### outputs_json contract (required)

```json
{
  "expectedOutputs": ["ga4_sessions", "gsc_clicks"],
  "actualOutputs": ["ga4_sessions"],
  "missingOutputs": ["gsc_clicks"],
  "metrics": { "ga4_sessions": 1234 },
  "debug": { "requested": "...", "status": 200 }
}
```

Important:

* For `run_type="connection"`, `expectedOutputs` should be `["worker_health"]`
* For `run_type="smoke"`, expectedOutputs come from the service catalog

---

## 3) Implement “Test Connections” endpoint

### Endpoint

`POST /api/integrations/test-connections?site_id=...`

### Behavior

For each service (built):

1. Load worker config from Bitwarden
2. Call `GET {base_url}/health` (or configured health path)
3. Write `service_run` with:

   * run_type = connection
   * status = success/fail
   * actualOutputs = `["worker_health"]` only if 200
   * missingOutputs = `[]` (connection mode doesn’t track business outputs)

UI should show:

* Connection status (optional column or in Diagnostics view)
* But **do not** treat connection tests as “service outputs validated.”

---

## 4) Implement “Run Smoke Tests” endpoint

### Endpoint

`POST /api/integrations/run-smoke-tests?site_id=...`

### Behavior

For each service (built + ready):

1. Create `service_run` run_type=smoke status=running
2. Call worker start endpoint with `mode=smoke`:

   * tiny payload
   * low cost
   * short timeout
3. If synchronous response:

   * extract `actualOutputs` + `metrics`
   * compute `missingOutputs = expected - actual`
   * status = success/partial/failed
4. If async response (202 jobId):

   * status = running
   * outputs_json.actualOutputs = ["job_started"]
   * missingOutputs should display as “pending” until job completes
   * polling on Refresh resolves final outputs + missing

### Status logic

* success: missingOutputs.length == 0
* partial: missingOutputs.length > 0 but some outputs present
* failed: no outputs or error

---

## 5) Missing outputs must appear in both places (table + inspector)

### A) Integrations table “Missing” column

Show:

* `missingOutputs.length`
* clickable → popover listing missing slugs (human labels)

Also show “Pending” if run is running async.

### B) Service inspector modal

In the inspector:

* Expected Outputs (already there)
* Add “Last Smoke Test Results” section:

  * Returned outputs list (with counts)
  * Missing outputs list (with explanation)

Use the latest `run_type="smoke"` run for that service/site.

---

## 6) Add “Show Missing on homepage” (site dashboard)

If you want missing on the main dashboard (not just integrations), add:

### Endpoint

`GET /api/sites/:site_id/health-summary`

Return:

* services failing
* services partial with missing outputs
* top missing outputs across services

Then show a “System Health” widget:

* “3 services partial”
* “Content Generator: 4 missing”
* “Crawler: 2 missing”
  etc.

---

## 7) Fix the current problem: “tested” with no real work

Right now your “Test All Services” is likely only checking reachability. Rename it to what it actually does:

* Current behavior → “Test Connections”
* New behavior → “Run Smoke Tests”

Make it impossible to confuse the two in the UI.

---

## 8) Acceptance criteria (non-negotiable)

After implementation:

1. Clicking **Test Connections**

* updates connection status
* does NOT change missing outputs (business outputs not tested)

2. Clicking **Run Smoke Tests**

* creates smoke runs
* updates missing outputs in:

  * Integrations table
  * inspector modal
* sets status success/partial/failed based on missing outputs

3. For async workers

* shows “Running/Pending” until results are in
* Refresh resolves them

---

If you want, I can also give you the exact “smoke payload” per service (Google, SERP, crawler, vitals, backlinks, notifications, content generator) so every test is fast and cheap but still meaningful.
