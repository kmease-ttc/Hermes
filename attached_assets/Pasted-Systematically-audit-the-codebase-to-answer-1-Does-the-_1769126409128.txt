Systematically audit the codebase to answer:
	1.	Does the current implementation match the PRDs?
	2.	Where does behavior deviate from documented contracts?
	3.	Which deviations are critical vs acceptable gaps?
	4.	What must be changed to reach PRD compliance?

‚∏ª

üß≠ Audit Scope (What to Inspect)

You must inspect:

1Ô∏è‚É£ Architecture Alignment
	‚Ä¢	Are Hermes, Agents, Socrates, and Deployer separated as specified?
	‚Ä¢	Are responsibilities cleanly enforced?
	‚Ä¢	Are there any components violating boundaries?

‚∏ª

2Ô∏è‚É£ Hermes Decision Engine

Verify:
	‚Ä¢	Hermes is the only system assigning priority
	‚Ä¢	Phased output (Week 1 / 2 / 3) is enforced
	‚Ä¢	Conflict handling exists and is annotated
	‚Ä¢	Change velocity limits are respected
	‚Ä¢	‚ÄúFix Everything‚Äù applies only to current week

‚∏ª

3Ô∏è‚É£ Agent Contracts

Verify:
	‚Ä¢	Agents emit only findings, evidence, and candidate actions
	‚Ä¢	Agents do not emit execution steps or priority
	‚Ä¢	Geographic scope (geo_scope) is required and respected
	‚Ä¢	Output schemas are validated
	‚Ä¢	Agent versioning is present
	‚Ä¢	Agents never block a run

‚∏ª

4Ô∏è‚É£ Execution / Deployer

Verify:
	‚Ä¢	Execution is strictly downstream of Hermes
	‚Ä¢	Only allowed change types are applied
	‚Ä¢	Idempotency is enforced
	‚Ä¢	Rollback paths exist
	‚Ä¢	Partial failures are handled safely
	‚Ä¢	Execution logs are emitted correctly

‚∏ª

5Ô∏è‚É£ Socrates & Learning

Verify:
	‚Ä¢	Logs are ingested centrally
	‚Ä¢	Weekly synthesis exists or is stubbed
	‚Ä¢	Doctrine vs heuristics are conceptually separated
	‚Ä¢	Agents do not read the knowledge base directly
	‚Ä¢	Hermes consumes learning indirectly

‚∏ª

6Ô∏è‚É£ Configuration & Settings

Verify:
	‚Ä¢	Account vs site config separation
	‚Ä¢	Config changes trigger re-analysis correctly
	‚Ä¢	Config versioning exists
	‚Ä¢	Safe defaults are enforced
	‚Ä¢	Missing config blocks analysis appropriately

‚∏ª

7Ô∏è‚É£ Observability & Audit

Verify:
	‚Ä¢	Required events are logged
	‚Ä¢	User-visible explanations exist or are planned
	‚Ä¢	‚ÄúWhy did Hermes do this?‚Äù is traceable
	‚Ä¢	Debug vs production visibility is respected

‚∏ª

8Ô∏è‚É£ UI/UX Compliance

Verify:
	‚Ä¢	Dashboard matches design standards
	‚Ä¢	Brand colors and gradients are consistent
	‚Ä¢	Accessibility basics are met
	‚Ä¢	Locked features are visible but gated
	‚Ä¢	No UI violates documented UX rules

‚∏ª

üßæ Output Format (Strict)

Your output must be structured as follows:

‚úÖ Conforms

List components or behaviors that fully match PRDs.

‚ö†Ô∏è Partial / Gaps

List areas where:
	‚Ä¢	Implementation is incomplete
	‚Ä¢	Behavior exists but violates a PRD
	‚Ä¢	Temporary shortcuts were taken

For each, include:
	‚Ä¢	File(s)
	‚Ä¢	PRD reference
	‚Ä¢	Risk level (Low / Medium / High)

‚∏ª

‚ùå Violations

List any hard PRD violations.

For each, include:
	‚Ä¢	Exact PRD section violated
	‚Ä¢	Code location
	‚Ä¢	Why this is unsafe or incorrect
	‚Ä¢	Required fix

‚∏ª

üîß Recommended Next Actions

A prioritized list of fixes to reach compliance.

‚∏ª

üö´ Rules (Non-Negotiable)
	‚Ä¢	Do not invent new behavior
	‚Ä¢	Do not weaken PRD rules
	‚Ä¢	Do not rationalize violations
	‚Ä¢	If something is ambiguous, call it out
	‚Ä¢	If something is missing, say so

When unsure:

Flag the gap. Do not guess.

‚∏ª

üß† Success Criteria

This audit is successful if:
	‚Ä¢	A human can understand system risk at a glance
	‚Ä¢	PRD compliance status is obvious
	‚Ä¢	Next steps are clear and actionable
	‚Ä¢	No part of the system remains a ‚Äúblack box‚Äù

‚∏ª

üèÅ Final Instruction

Proceed methodically.
PRDs are law.
Clarity beats speed.